# Solar Power Prediction with Bigger Dataset + Improved Models
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score
import matplotlib.pyplot as plt

# 1. Generate Synthetic Dataset (500 samples)
np.random.seed(42)
temperature = np.random.randint(15, 45, 500)   # Â°C
humidity = np.random.randint(20, 90, 500)      # %
wind_speed = np.random.randint(2, 25, 500)     # km/h

# A synthetic function for solar output (depends on temperature, humidity, wind)
solar_output = (
    0.15 * temperature 
    - 0.05 * humidity 
    + 0.1 * wind_speed 
    + np.random.normal(0, 1, 500)   # noise
)
solar_output = np.clip(solar_output, 0.5, 8.0)  # realistic bounds (kWh)
df = pd.DataFrame({
    "temperature": temperature,
    "humidity": humidity,
    "wind_speed": wind_speed,
    "solar_output": solar_output
})

# 2. Regression Target & Classification Labels
def categorize_output(val):
    if val < 2.5:
        return "Low"
    elif 2.5 <= val < 5:
        return "Medium"
    else:
        return "High"
df["solar_class"] = df["solar_output"].apply(categorize_output)
X = df[["temperature", "humidity", "wind_speed"]]
y_reg = df["solar_output"]
y_class = df["solar_class"]

# 3. Train-Test Split
X_train, X_test, y_train_reg, y_test_reg = train_test_split(X, y_reg, test_size=0.2, random_state=42)
_, X_test_cls, _, y_test_cls = train_test_split(X, y_class, test_size=0.2, random_state=42)
# 4. Regression Model (Random Forest with Cross-Validation)
reg_model = RandomForestRegressor(n_estimators=200, random_state=42)
reg_model.fit(X_train, y_train_reg)
y_pred_reg = reg_model.predict(X_test)
print("ðŸ”¹ Regression Metrics:")
print("MSE:", mean_squared_error(y_test_reg, y_pred_reg))
print("R2 Score:", r2_score(y_test_reg, y_pred_reg))
cv_scores = cross_val_score(reg_model, X, y_reg, cv=5, scoring="r2")
print("Cross-Validation R2 (avg):", cv_scores.mean())

# 5. Direct Classification Model
clf = RandomForestClassifier(n_estimators=200, random_state=42)
clf.fit(X_train, y_train_reg.apply(categorize_output))
y_pred_class = clf.predict(X_test_cls)
print("\nðŸ”¹ Classification Metrics:")
print("Accuracy:", accuracy_score(y_test_cls, y_pred_class))

# 6. Results Table
results = pd.DataFrame({
    "Actual_Output": y_test_reg.values[:10],
    "Predicted_Output": y_pred_reg[:10],
    "Actual_Class": y_test_cls.values[:10],
    "Predicted_Class": y_pred_class[:10]
})
print("\nSample Results (first 10 rows):\n", results)

# 7. Visualization
plt.figure(figsize=(12, 5))
# Regression: Actual vs Predicted
plt.subplot(1, 2, 1)
plt.scatter(y_test_reg, y_pred_reg, color='blue', alpha=0.6)
plt.plot([min(y_test_reg), max(y_test_reg)],
         [min(y_test_reg), max(y_test_reg)], 'r--')
plt.xlabel("Actual Solar Output (kWh)")
plt.ylabel("Predicted Solar Output (kWh)")
plt.title("Regression: Actual vs Predicted")

# Classification: Actual vs Predicted Classes
plt.subplot(1, 2, 2)
plt.scatter(range(len(y_test_cls)), y_test_cls, color='green', label='Actual Class')
plt.scatter(range(len(y_pred_class)), y_pred_class, color='orange', marker='x', label='Predicted Class')
plt.xlabel("Test Sample Index")
plt.ylabel("Class")
plt.title("Classification Results")
plt.legend()
plt.tight_layout()
plt.show()




# Solar Power Prediction using Deep Learning (Regression)
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# 1. Sample Dataset
data = {
    "temperature": [25, 30, 28, 35, 20, 22, 31, 33, 27, 29],
    "humidity": [60, 50, 55, 45, 70, 65, 52, 48, 58, 53],
    "wind_speed": [5, 3, 4, 2, 6, 5, 3, 2, 4, 3],
    "solar_irradiance": [400, 600, 550, 700, 300, 350, 650, 680, 500, 580],
    "solar_power": [50, 120, 100, 150, 40, 55, 130, 140, 95, 110]
}
df = pd.DataFrame(data)

# 2. Split Data into Features and Target
X = df[["temperature", "humidity", "wind_speed", "solar_irradiance"]]
y = df["solar_power"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Feature Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. Build Deep Learning Model
model = Sequential([
    Dense(64, input_dim=4, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(1)  # Output layer for regression
])
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# 5. Train the Model
history = model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, validation_split=0.2, verbose=0)

# 6. Evaluate the Model
y_pred = model.predict(X_test_scaled).flatten()
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse:.2f}")
print(f"R2 Score: {r2:.2f}")

# 7. Predict for All 10 Samples
X_scaled = scaler.transform(X)  # Scale full dataset
y_pred_all = model.predict(X_scaled).flatten()
print("\n--- Predicted vs Actual Solar Power ---")
for i in range(len(y)):
    print(f"Sample {i+1}: Actual = {y.iloc[i]} kWh, Predicted = {y_pred_all[i]:.2f} kWh")

# 8. Plot Predictions vs Actual
plt.scatter(y_test, y_pred)
plt.xlabel("Actual Solar Power (kWh)")
plt.ylabel("Predicted Solar Power (kWh)")
plt.title("Actual vs Predicted Solar Power")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')
plt.show()
# 9. Plot Training Loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss (MSE)')
plt.title('Training History')
plt.legend()
plt.show()




# Electricity Load Forecasting using Classification (ML)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns

# 1. Generate Synthetic Dataset
np.random.seed(42)
n_samples = 500
temperature = np.random.uniform(10, 40, n_samples)        # Â°C
humidity = np.random.uniform(20, 90, n_samples)           # %
day_of_week = np.random.randint(0, 7, n_samples)          # 0=Mon, 6=Sun
hour_of_day = np.random.randint(0, 24, n_samples)         # 0-23

# Synthetic continuous electricity load
load = (
    200 + (temperature * 8) - (humidity * 2) +
    (hour_of_day * 5) + (day_of_week * 10) +
    np.random.normal(0, 30, n_samples)
)
# Convert load into categorical classes: Low / Medium / High
bins = [0, 400, 700, np.inf]
labels = ["Low", "Medium", "High"]
load_class = pd.cut(load, bins=bins, labels=labels)
data = pd.DataFrame({
    "Temperature": temperature,
    "Humidity": humidity,
    "DayOfWeek": day_of_week,
    "HourOfDay": hour_of_day,
    "LoadClass": load_class
})

# 2. Split Data
X = data[["Temperature", "Humidity", "DayOfWeek", "HourOfDay"]]
y = data["LoadClass"]
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 3. Feature Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. Train Classification Model
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train_scaled, y_train)

# 5. Predictions
y_pred = clf.predict(X_test_scaled)

# 6. Evaluation Metrics
print("Electricity Load Forecasting âš¡ (Classification)")
print("-----------------------------------------------")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred, labels=labels)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=labels, yticklabels=labels)
plt.xlabel("Predicted Class")
plt.ylabel("Actual Class")
plt.title("Confusion Matrix - Electricity Load Classification")
plt.show()



# Electricity Load Forecasting using Classification (ML)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns

# 1. Generate Synthetic Dataset
np.random.seed(42)
n_samples = 500
temperature = np.random.uniform(10, 40, n_samples)        # Â°C
humidity = np.random.uniform(20, 90, n_samples)           # %
day_of_week = np.random.randint(0, 7, n_samples)          # 0=Mon, 6=Sun
hour_of_day = np.random.randint(0, 24, n_samples)         # 0-23

# Synthetic continuous electricity load
load = (
    200 + (temperature * 8) - (humidity * 2) +
    (hour_of_day * 5) + (day_of_week * 10) +
    np.random.normal(0, 30, n_samples)
)
# Convert load into categorical classes: Low / Medium / High
bins = [0, 400, 700, np.inf]
labels = ["Low", "Medium", "High"]
load_class = pd.cut(load, bins=bins, labels=labels)
data = pd.DataFrame({
    "Temperature": temperature,
    "Humidity": humidity,
    "DayOfWeek": day_of_week,
    "HourOfDay": hour_of_day,
    "LoadClass": load_class
})

# 2. Split Data
X = data[["Temperature", "Humidity", "DayOfWeek", "HourOfDay"]]
y = data["LoadClass"]
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 3. Feature Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. Train Classification Model
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train_scaled, y_train)

# 5. Predictions
y_pred = clf.predict(X_test_scaled)

# 6. Evaluation Metrics
print("Electricity Load Forecasting âš¡ (Classification)")
print("-----------------------------------------------")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred, labels=labels)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=labels, yticklabels=labels)
plt.xlabel("Predicted Class")
plt.ylabel("Actual Class")
plt.title("Confusion Matrix - Electricity Load Classification")
plt.show()




# Electricity Load Forecasting using Classification (Deep Learning)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import tensorflow as tf
from tensorflow.keras import layers, models

# 1. Generate Synthetic Dataset
np.random.seed(42)
n_samples = 1000
temperature = np.random.uniform(10, 40, n_samples)        # Â°C
humidity = np.random.uniform(20, 90, n_samples)           # %
day_of_week = np.random.randint(0, 7, n_samples)          # 0=Mon, 6=Sun
hour_of_day = np.random.randint(0, 24, n_samples)         # 0-23

# Synthetic continuous load
load = (
    200 + (temperature * 8) - (humidity * 2) +
    (hour_of_day * 5) + (day_of_week * 10) +
np.random.normal(0, 30, n_samples)
)

# Convert load into categorical classes
bins = [0, 400, 700, np.inf]
labels = ["Low", "Medium", "High"]
load_class = pd.cut(load, bins=bins, labels=labels)
data = pd.DataFrame({
    "Temperature": temperature,
    "Humidity": humidity,
    "DayOfWeek": day_of_week,
    "HourOfDay": hour_of_day,
    "LoadClass": load_class
})

# 2. Prepare Features and Labels
X = data[["Temperature", "Humidity", "DayOfWeek", "HourOfDay"]].values
y = data["LoadClass"]

# Encode categorical labels into integers
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# One-hot encode for DL classification
y_onehot = tf.keras.utils.to_categorical(y_encoded)
# Split into train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y_onehot, test_size=0.2, random_state=42, stratify=y_onehot
)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 3. Build Deep Learning Model
model = models.Sequential([
    layers.Dense(64, activation="relu", input_shape=(X_train_scaled.shape[1],)),
    layers.Dropout(0.3),
    layers.Dense(32, activation="relu"),
    layers.Dense(y_onehot.shape[1], activation="softmax")   # 3 output classes
])
model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

# 4. Train Model
history = model.fit(
    X_train_scaled, y_train,
    validation_split=0.2,
    epochs=30,
    batch_size=16,
    verbose=1
)

# 5. Evaluate Model
y_pred_probs = model.predict(X_test_scaled)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = np.argmax(y_test, axis=1)
print("Electricity Load Forecasting âš¡ with Deep Learning (Classification)")
print("-----------------------------------------------------------------")
print("Accuracy:", accuracy_score(y_true, y_pred))
print("\nClassification Report:\n", classification_report(y_true, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=label_encoder.classes_,
            yticklabels=label_encoder.classes_)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - DL Electricity Load Classification")
plt.show()

# 6. Training Performance Plot
plt.figure(figsize=(8,5))
plt.plot(history.history['accuracy'], label="Train Accuracy")
plt.plot(history.history['val_accuracy'], label="Val Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Training & Validation Accuracy")
plt.legend()
plt.show()
